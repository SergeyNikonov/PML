---
title: "Practical Machine Learning Course Project Writeup"
output:
  html_document:
    keep_md: yes
---

*by Sergey Nikonov*

We have huge dataset from  quantified self movement devices and want to predict manner in which persons did the exercise.

Let's load the data and take a look at it.

```{r}
data <- read.csv(file="pml-training.csv", stringsAsFactors=F, sep=",")
dim(data)
table(is.na(data))
```

Many variables, many NAs. Let's take out variables with NAs, near zero variance and not needed for prediction (perhaps).

```{r }
library(caret)
data <- data[-nearZeroVar(data)]
nas <- sapply(data[,1:100], function(x) table(is.na(x))[1])
data <- data[, nas==19622]
data <- data[, c(-1,-3:-7)]
```

And what about correlation?

```{r}
table(symnum(cor(data[,c(-1, -53)])))
attr(symnum(cor(data[, c(-1, -53)])), "legend")

```

Some preprocessing will be good.

```{r}
pre <- preProcess(data[c(-1, -53)], method="pca", thresh=0.95)
predata <- predict(pre, data[ c(-1, -53)])
```

Now we can take a look into preprocessed data. 25 variables are better than 160.

```{r}
qplot(predata[,1], predata[,2], color=data[,53])
```

We have 5 exellent clusters, but they look like a mess. It is person's clusters, may be.

```{r}
qplot(predata[,1], predata[,2], color=data[,1])
```

OK then. At least we can differentiate persons.

Seems like we can not divide "classe" in 2 dimensions, so let's algorithm do it for us.
```{r}
pairs(predata[,16:20], col=as.factor(data[,53]))
```

I had two choices: a) use something strong as boosting or random forest o b) find something simple and accurate enough. After digging in caret models I found k-nearest neighbors. Let's try.

```{r}
library(caret)

data[,53] <- as.factor(data[,53])
tr <-  trainControl( method="cv", number=3, p=0.3)
tune <- data.frame(k=1:3)
fit <- train(y=data[,53], x=predata, tuneGrid=tune, trControl=tr, 
             method="knn" )
fit
plot(varImp(fit), scales=list(cex=0.5))
```

Hm. Exellent accuracy and Kappa. May be overfitting? Whatever. Create a prediction and compare to another.


```{r}
test <- read.csv(file="pml-testing.csv", stringsAsFactors=F, sep=",")
test <- test[,names(test) %in% names(data)]
pretest <- predict(pre, test[,-1])
preKnn <- predict(fit, pretest)
```

If it is a prediction, here must be a random forest. Just to make sure.

```{r}
library(doParallel)
tr <-  trainControl(method="cv", number=3,  p=0.3)

cl <- makePSOCKcluster(2)
clusterEvalQ(cl, library(foreach))
registerDoParallel(cl)
fitRF <- train(y=data[,53], x=predata, trControl=tr,  method="parRF")
fitRF
plot(varImp(fitRF), scales=list(cex=0.7))
preRF <- predict(fitRF, pretest)
```

Notice size of fit (7.9 Mb) and fitRF (64.5 Mb).

And the moment of truth.

```{r}

confusionMatrix(predict(fit, predata), data$classe) 
confusionMatrix(predict(fitRF, predata), data$classe) 
all.equal(preRF, preKnn)
```

OK. Submission next. And good luck for all of us.